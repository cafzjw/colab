{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xIckrfN649f0SoBeneMAPxS0L0qOSPbL",
      "authorship_tag": "ABX9TyNPRJaSqmxs4UW/GFs+c9Gv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzjcaf/colab/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "6NSCEuR_MH9p"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([transforms.Resize([32,32]),transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "fuY-0VxAC2PO"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mydataset(Dataset):\n",
        "  def __init__(self,root,img_data,label_data,transform):\n",
        "    self.root_dir = root\n",
        "    self.img_dir = img_data\n",
        "    self.label_dir = label_data\n",
        "    self.img_path = os.path.join(self.root_dir,self.img_dir)\n",
        "    self.label_path = os.path.join(self.root_dir,self.label_dir)\n",
        "    self.img_list = os.listdir(self.img_path)\n",
        "    self.label_list = os.listdir(self.label_path)\n",
        "    self.transforms = transform\n",
        "    self.img_list.sort()\n",
        "    self.label_list.sort()\n",
        "  def __getitem__(self,idx):\n",
        "    img_name = self.img_list[idx]\n",
        "    label_name = self.label_list[idx]\n",
        "    img_idx_path = os.path.join(self.root_dir,self.img_dir,img_name)\n",
        "    label_idx_path = os.path.join(self.root_dir,self.label_dir,label_name)\n",
        "    #图像\n",
        "    img = Image.open(img_idx_path)\n",
        "    img = self.transforms(img)\n",
        "    #标签\n",
        "    label = Image.open(label_idx_path)\n",
        "    label = self.transforms(label)\n",
        "    return img,label\n",
        "  def __len__(self):\n",
        "    #assert len(self.img_list) == len(self.label_list)\n",
        "    return len(self.img_list)"
      ],
      "metadata": {
        "id": "IS602n45k9AS"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_root = \"/content/drive/MyDrive/data/train\"\n",
        "test_root = \"/content/drive/MyDrive/data/test\"\n",
        "lab = \"lab\"\n",
        "img = \"img\""
      ],
      "metadata": {
        "id": "T-J_ZYdJtfx8"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = Mydataset(train_root,img,lab,data_transform)\n",
        "testdata = Mydataset(test_root,img,lab,data_transform)"
      ],
      "metadata": {
        "id": "YdyVdgvJt2Gy"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "train_dataset = DataLoader(traindata,batch_size,shuffle=True)\n",
        "test_dataset = DataLoader(testdata,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "bJm2GMVsvvQt"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "model = UNet(3,1)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "summary(model,(batch_size,3,32,32))"
      ],
      "metadata": {
        "id": "2aRIy9FsRDZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da5a3b8-b233-4c59-9097-6c8b6d1c30b5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "UNet                                          [4, 1, 32, 32]            --\n",
              "├─DoubleConv: 1-1                             [4, 64, 32, 32]           --\n",
              "│    └─Sequential: 2-1                        [4, 64, 32, 32]           --\n",
              "│    │    └─Conv2d: 3-1                       [4, 64, 32, 32]           1,728\n",
              "│    │    └─BatchNorm2d: 3-2                  [4, 64, 32, 32]           128\n",
              "│    │    └─ReLU: 3-3                         [4, 64, 32, 32]           --\n",
              "│    │    └─Conv2d: 3-4                       [4, 64, 32, 32]           36,864\n",
              "│    │    └─BatchNorm2d: 3-5                  [4, 64, 32, 32]           128\n",
              "│    │    └─ReLU: 3-6                         [4, 64, 32, 32]           --\n",
              "├─Down: 1-2                                   [4, 128, 16, 16]          --\n",
              "│    └─Sequential: 2-2                        [4, 128, 16, 16]          --\n",
              "│    │    └─MaxPool2d: 3-7                    [4, 64, 16, 16]           --\n",
              "│    │    └─DoubleConv: 3-8                   [4, 128, 16, 16]          221,696\n",
              "├─Down: 1-3                                   [4, 256, 8, 8]            --\n",
              "│    └─Sequential: 2-3                        [4, 256, 8, 8]            --\n",
              "│    │    └─MaxPool2d: 3-9                    [4, 128, 8, 8]            --\n",
              "│    │    └─DoubleConv: 3-10                  [4, 256, 8, 8]            885,760\n",
              "├─Down: 1-4                                   [4, 512, 4, 4]            --\n",
              "│    └─Sequential: 2-4                        [4, 512, 4, 4]            --\n",
              "│    │    └─MaxPool2d: 3-11                   [4, 256, 4, 4]            --\n",
              "│    │    └─DoubleConv: 3-12                  [4, 512, 4, 4]            3,540,992\n",
              "├─Down: 1-5                                   [4, 512, 2, 2]            --\n",
              "│    └─Sequential: 2-5                        [4, 512, 2, 2]            --\n",
              "│    │    └─MaxPool2d: 3-13                   [4, 512, 2, 2]            --\n",
              "│    │    └─DoubleConv: 3-14                  [4, 512, 2, 2]            4,720,640\n",
              "├─Up: 1-6                                     [4, 256, 4, 4]            --\n",
              "│    └─Upsample: 2-6                          [4, 512, 4, 4]            --\n",
              "│    └─DoubleConv: 2-7                        [4, 256, 4, 4]            --\n",
              "│    │    └─Sequential: 3-15                  [4, 256, 4, 4]            5,899,776\n",
              "├─Up: 1-7                                     [4, 128, 8, 8]            --\n",
              "│    └─Upsample: 2-8                          [4, 256, 8, 8]            --\n",
              "│    └─DoubleConv: 2-9                        [4, 128, 8, 8]            --\n",
              "│    │    └─Sequential: 3-16                  [4, 128, 8, 8]            1,475,328\n",
              "├─Up: 1-8                                     [4, 64, 16, 16]           --\n",
              "│    └─Upsample: 2-10                         [4, 128, 16, 16]          --\n",
              "│    └─DoubleConv: 2-11                       [4, 64, 16, 16]           --\n",
              "│    │    └─Sequential: 3-17                  [4, 64, 16, 16]           369,024\n",
              "├─Up: 1-9                                     [4, 64, 32, 32]           --\n",
              "│    └─Upsample: 2-12                         [4, 64, 32, 32]           --\n",
              "│    └─DoubleConv: 2-13                       [4, 64, 32, 32]           --\n",
              "│    │    └─Sequential: 3-18                  [4, 64, 32, 32]           110,848\n",
              "├─OutConv: 1-10                               [4, 1, 32, 32]            --\n",
              "│    └─Conv2d: 2-14                           [4, 1, 32, 32]            65\n",
              "===============================================================================================\n",
              "Total params: 17,262,977\n",
              "Trainable params: 17,262,977\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 2.50\n",
              "===============================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 29.92\n",
              "Params size (MB): 69.05\n",
              "Estimated Total Size (MB): 99.02\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self,weight=None,size_average=True):\n",
        "        super(DiceLoss,self).__init__()\n",
        "        \n",
        "    def forward(self,inputs,targets,smooth=1):\n",
        "        inputs = torch.sigmoid(inputs)       \n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()                   \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        return 1 - dice"
      ],
      "metadata": {
        "id": "oDrDS8ONMzXG"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = DiceLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8, momentum=0.5)"
      ],
      "metadata": {
        "id": "v6bYFEvBo-2P"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_dataset)\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (img, label) in enumerate(train_dataset):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(img)\n",
        "        \n",
        "        loss = criterion(outputs, label)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "id": "4LjjfoRpEiyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecd20a4-53e0-4c55-9461-972ac0ae055f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [1/12], Loss: 0.9924\n",
            "Epoch [1/2], Step [2/12], Loss: 0.9904\n",
            "Epoch [1/2], Step [3/12], Loss: 0.9923\n",
            "Epoch [1/2], Step [4/12], Loss: 0.9860\n",
            "Epoch [1/2], Step [5/12], Loss: 0.9882\n",
            "Epoch [1/2], Step [6/12], Loss: 0.9842\n",
            "Epoch [1/2], Step [7/12], Loss: 0.9921\n",
            "Epoch [1/2], Step [8/12], Loss: 0.9861\n",
            "Epoch [1/2], Step [9/12], Loss: 0.9850\n",
            "Epoch [1/2], Step [10/12], Loss: 0.9859\n",
            "Epoch [1/2], Step [11/12], Loss: 0.9896\n",
            "Epoch [1/2], Step [12/12], Loss: 0.9899\n",
            "Epoch [2/2], Step [1/12], Loss: 0.9869\n",
            "Epoch [2/2], Step [2/12], Loss: 0.9912\n",
            "Epoch [2/2], Step [3/12], Loss: 0.9866\n",
            "Epoch [2/2], Step [4/12], Loss: 0.9881\n",
            "Epoch [2/2], Step [5/12], Loss: 0.9845\n",
            "Epoch [2/2], Step [6/12], Loss: 0.9863\n",
            "Epoch [2/2], Step [7/12], Loss: 0.9812\n",
            "Epoch [2/2], Step [8/12], Loss: 0.9847\n",
            "Epoch [2/2], Step [9/12], Loss: 0.9886\n",
            "Epoch [2/2], Step [10/12], Loss: 0.9847\n",
            "Epoch [2/2], Step [11/12], Loss: 0.9837\n",
            "Epoch [2/2], Step [12/12], Loss: 0.9835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for img, label in test_dataset:\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        outputs = model(img)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (predicted == label).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "id": "yWt1PBJuYXP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7722bdeb-8755-4226-dba3-17e67e9c9044"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 289152.17391304346 %\n"
          ]
        }
      ]
    }
  ]
}