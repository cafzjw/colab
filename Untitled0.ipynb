{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xIckrfN649f0SoBeneMAPxS0L0qOSPbL",
      "authorship_tag": "ABX9TyN0aHwfDjLIr1o+/zoEEZfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzjcaf/colab/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "#import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "6NSCEuR_MH9p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([transforms.Resize(320),transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "fuY-0VxAC2PO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mydataset(Dataset):\n",
        "  def __init__(self,root,img_data,label_data,transform):\n",
        "    self.root_dir = root\n",
        "    self.img_dir = img_data\n",
        "    self.label_dir = label_data\n",
        "    self.img_path = os.path.join(self.root_dir,self.img_dir)\n",
        "    self.label_path = os.path.join(self.root_dir,self.label_dir)\n",
        "    self.img_list = os.listdir(self.img_path)\n",
        "    self.label_list = os.listdir(self.label_path)\n",
        "    self.transforms = transform\n",
        "    self.img_list.sort()\n",
        "    self.label_list.sort()\n",
        "  def __getitem__(self,idx):\n",
        "    img_name = self.img_list[idx]\n",
        "    label_name = self.label_list[idx]\n",
        "    img_idx_path = os.path.join(self.root_dir,self.img_dir,img_name)\n",
        "    label_idx_path = os.path.join(self.root_dir,self.label_dir,label_name)\n",
        "    #图像\n",
        "    img = Image.open(img_idx_path)\n",
        "    img = self.transforms(img)\n",
        "    #标签\n",
        "    label = Image.open(label_idx_path)\n",
        "    label = self.transforms(label)\n",
        "    return img,label\n",
        "  def __len__(self):\n",
        "    #assert len(self.img_list) == len(self.label_list)\n",
        "    return len(self.img_list)"
      ],
      "metadata": {
        "id": "IS602n45k9AS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_root = \"/content/drive/MyDrive/data/train\"\n",
        "test_root = \"/content/drive/MyDrive/data/test\"\n",
        "lab = \"lab\"\n",
        "img = \"img\""
      ],
      "metadata": {
        "id": "T-J_ZYdJtfx8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = Mydataset(train_root,img,lab,data_transform)\n",
        "testdata = Mydataset(test_root,img,lab,data_transform)"
      ],
      "metadata": {
        "id": "YdyVdgvJt2Gy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "train_dataset = DataLoader(traindata,batch_size,shuffle=True)\n",
        "test_dataset = DataLoader(testdata,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "bJm2GMVsvvQt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "model = UNet(3,1)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "2aRIy9FsRDZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de22ef88-40e6-46b8-8824-a8efe955c5af"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (inc): DoubleConv(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (down1): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down4): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up1): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (outc): OutConv(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self,weight=None,size_average=True):\n",
        "        super(DiceLoss,self).__init__()\n",
        "        \n",
        "    def forward(self,inputs,targets,smooth=1):\n",
        "        inputs = torch.sigmoid(inputs)       \n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()                   \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        return 1 - dice"
      ],
      "metadata": {
        "id": "oDrDS8ONMzXG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = DiceLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8, momentum=0.5)"
      ],
      "metadata": {
        "id": "v6bYFEvBo-2P"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_dataset)\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (img, label) in enumerate(train_dataset):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(img)\n",
        "        #print(outputs.size())\n",
        "        loss = criterion(outputs, label)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 1 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "id": "4LjjfoRpEiyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead0e8fc-7e50-4dc0-9b77-24c7817ae070"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [1/12], Loss: 0.9901\n",
            "Epoch [1/5], Step [2/12], Loss: 0.9889\n",
            "Epoch [1/5], Step [3/12], Loss: 0.9882\n",
            "Epoch [1/5], Step [4/12], Loss: 0.9888\n",
            "Epoch [1/5], Step [5/12], Loss: 0.9828\n",
            "Epoch [1/5], Step [6/12], Loss: 0.9869\n",
            "Epoch [1/5], Step [7/12], Loss: 0.9870\n",
            "Epoch [1/5], Step [8/12], Loss: 0.9829\n",
            "Epoch [1/5], Step [9/12], Loss: 0.9822\n",
            "Epoch [1/5], Step [10/12], Loss: 0.9800\n",
            "Epoch [1/5], Step [11/12], Loss: 0.9799\n",
            "Epoch [1/5], Step [12/12], Loss: 0.9817\n",
            "Epoch [2/5], Step [1/12], Loss: 0.9813\n",
            "Epoch [2/5], Step [2/12], Loss: 0.9781\n",
            "Epoch [2/5], Step [3/12], Loss: 0.9793\n",
            "Epoch [2/5], Step [4/12], Loss: 0.9825\n",
            "Epoch [2/5], Step [5/12], Loss: 0.9747\n",
            "Epoch [2/5], Step [6/12], Loss: 0.9769\n",
            "Epoch [2/5], Step [7/12], Loss: 0.9735\n",
            "Epoch [2/5], Step [8/12], Loss: 0.9691\n",
            "Epoch [2/5], Step [9/12], Loss: 0.9584\n",
            "Epoch [2/5], Step [10/12], Loss: 0.9721\n",
            "Epoch [2/5], Step [11/12], Loss: 0.9665\n",
            "Epoch [2/5], Step [12/12], Loss: 0.9591\n",
            "Epoch [3/5], Step [1/12], Loss: 0.9633\n",
            "Epoch [3/5], Step [2/12], Loss: 0.9578\n",
            "Epoch [3/5], Step [3/12], Loss: 0.9628\n",
            "Epoch [3/5], Step [4/12], Loss: 0.9369\n",
            "Epoch [3/5], Step [5/12], Loss: 0.9531\n",
            "Epoch [3/5], Step [6/12], Loss: 0.9329\n",
            "Epoch [3/5], Step [7/12], Loss: 0.9161\n",
            "Epoch [3/5], Step [8/12], Loss: 0.9137\n",
            "Epoch [3/5], Step [9/12], Loss: 0.9454\n",
            "Epoch [3/5], Step [10/12], Loss: 0.9518\n",
            "Epoch [3/5], Step [11/12], Loss: 0.9488\n",
            "Epoch [3/5], Step [12/12], Loss: 0.9129\n",
            "Epoch [4/5], Step [1/12], Loss: 0.9111\n",
            "Epoch [4/5], Step [2/12], Loss: 0.8580\n",
            "Epoch [4/5], Step [3/12], Loss: 0.8648\n",
            "Epoch [4/5], Step [4/12], Loss: 0.9378\n",
            "Epoch [4/5], Step [5/12], Loss: 0.9777\n",
            "Epoch [4/5], Step [6/12], Loss: 0.9785\n",
            "Epoch [4/5], Step [7/12], Loss: 0.9638\n",
            "Epoch [4/5], Step [8/12], Loss: 0.9682\n",
            "Epoch [4/5], Step [9/12], Loss: 0.9337\n",
            "Epoch [4/5], Step [10/12], Loss: 0.9102\n",
            "Epoch [4/5], Step [11/12], Loss: 0.8726\n",
            "Epoch [4/5], Step [12/12], Loss: 0.9880\n",
            "Epoch [5/5], Step [1/12], Loss: 0.8904\n",
            "Epoch [5/5], Step [2/12], Loss: 0.8772\n",
            "Epoch [5/5], Step [3/12], Loss: 0.7476\n",
            "Epoch [5/5], Step [4/12], Loss: 0.8149\n",
            "Epoch [5/5], Step [5/12], Loss: 0.8141\n",
            "Epoch [5/5], Step [6/12], Loss: 0.9244\n",
            "Epoch [5/5], Step [7/12], Loss: 0.8685\n",
            "Epoch [5/5], Step [8/12], Loss: 0.7539\n",
            "Epoch [5/5], Step [9/12], Loss: 0.7664\n",
            "Epoch [5/5], Step [10/12], Loss: 0.7155\n",
            "Epoch [5/5], Step [11/12], Loss: 0.5721\n",
            "Epoch [5/5], Step [12/12], Loss: 0.5341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for img, label in test_dataset:\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        outputs = model(img)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (predicted == label).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "id": "yWt1PBJuYXP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3175016-9e28-4154-8c90-8dff071a96b0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 69391173.91304348 %\n"
          ]
        }
      ]
    }
  ]
}