{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fangzi6.14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Eybkjm7fUpo_Yi1GjKPSRZkLUkfbBai_",
      "authorship_tag": "ABX9TyNbmbkxSgkyZf9PiC1aNFIl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzjcaf/colab/blob/main/fangzi6_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "#from torchinfo import summary"
      ],
      "metadata": {
        "id": "6NSCEuR_MH9p"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "EUjrMFtbzKhs"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([transforms.Resize([50,50]),transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "fuY-0VxAC2PO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mydataset(Dataset):\n",
        "  def __init__(self,root,img_data,label_data,transform):\n",
        "    self.root_dir = root\n",
        "    self.img_dir = img_data\n",
        "    self.label_dir = label_data\n",
        "    self.img_path = os.path.join(self.root_dir,self.img_dir)\n",
        "    self.label_path = os.path.join(self.root_dir,self.label_dir)\n",
        "    self.img_list = os.listdir(self.img_path)\n",
        "    self.label_list = os.listdir(self.label_path)\n",
        "    self.transforms = transform\n",
        "    self.img_list.sort()\n",
        "    self.label_list.sort()\n",
        "  def __getitem__(self,idx):\n",
        "    img_name = self.img_list[idx]\n",
        "    label_name = self.label_list[idx]\n",
        "    img_idx_path = os.path.join(self.root_dir,self.img_dir,img_name)\n",
        "    label_idx_path = os.path.join(self.root_dir,self.label_dir,label_name)\n",
        "    #图像\n",
        "    img = Image.open(img_idx_path)\n",
        "    img = self.transforms(img)\n",
        "    #标签\n",
        "    label = Image.open(label_idx_path)\n",
        "    label = self.transforms(label)\n",
        "    label = label.squeeze(0)\n",
        "    label = label.to(torch.int64)\n",
        "    return img,label\n",
        "  def __len__(self):\n",
        "    #assert len(self.img_list) == len(self.label_list)\n",
        "    return len(self.img_list)"
      ],
      "metadata": {
        "id": "IS602n45k9AS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_root = \"/content/drive/MyDrive/data/train\"\n",
        "test_root = \"/content/drive/MyDrive/data/test\"\n",
        "lab = \"lab\"\n",
        "img = \"img\""
      ],
      "metadata": {
        "id": "T-J_ZYdJtfx8"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = Mydataset(train_root,img,lab,data_transform)\n",
        "testdata = Mydataset(test_root,img,lab,data_transform)"
      ],
      "metadata": {
        "id": "YdyVdgvJt2Gy"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "train_dataset = DataLoader(traindata,batch_size,shuffle=True)\n",
        "test_dataset = DataLoader(testdata,batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "bJm2GMVsvvQt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        \n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "model = UNet(3,2)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "#summary(model,(batch_size,3,32,32))"
      ],
      "metadata": {
        "id": "2aRIy9FsRDZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00b73e0-7b1c-4d2f-a945-0b733835d306"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (inc): DoubleConv(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (down1): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down4): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up1): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (outc): OutConv(\n",
              "    (conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8, momentum=0.5)"
      ],
      "metadata": {
        "id": "v6bYFEvBo-2P"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for img, label in train_dataset:\n",
        "      img = img.to(device)\n",
        "      #label = F.one_hot(label,num_classes=2)\n",
        "      #label (batch_size,256,256)\n",
        "      #label = torch.permute(label, (0,3,1,2))\n",
        "      #label = label.float()\n",
        "      label = label.to(device)\n",
        "      #print(label.shape)\n",
        "      # Forward pass\n",
        "      output = model(img)\n",
        "      #print(output.shape)\n",
        "      loss = criterion(output, label)\n",
        "        \n",
        "      # Backward and optimize\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      train_loss += loss.item()*img.size(0)\n",
        "    train_loss = train_loss/len(train_dataset.dataset)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
      ],
      "metadata": {
        "id": "oHARcSghyjUo"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(epoch):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_correct = 0.0\n",
        "  with torch.no_grad():\n",
        "        for img,label in test_dataset:\n",
        "          img = img.to(device)\n",
        "          label = label.to(device)\n",
        "          output = model(img)\n",
        "          #print(label.shape,output.shape)\n",
        "          loss = criterion(output,label)\n",
        "          running_loss += loss.item()*img.size(0)\n",
        "          running_correct += torch.sum(torch.argmax(output.data,1)==label.data)/(256*256)\n",
        "        epoch_loss = running_loss/len(test_dataset.dataset)\n",
        "        epoch_correct = running_correct/len(test_dataset.dataset)\n",
        "        print('Epoch: {} \\tval loss:{:.6f}  acc:{:.6f}'.format(epoch,epoch_loss,epoch_correct))"
      ],
      "metadata": {
        "id": "GFW-CVT_ylmW"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "  train(epoch)\n",
        "  val(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erg-L-E4yn0J",
        "outputId": "98d25797-8471-4f63-da06-593bf5e59df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.061666\n",
            "Epoch: 1 \tval loss:0.002029  acc:0.038147\n",
            "Epoch: 2 \tTraining Loss: 0.000001\n",
            "Epoch: 2 \tval loss:0.000055  acc:0.038147\n",
            "Epoch: 3 \tTraining Loss: 0.000001\n",
            "Epoch: 3 \tval loss:0.000004  acc:0.038147\n",
            "Epoch: 4 \tTraining Loss: 0.000001\n",
            "Epoch: 4 \tval loss:0.000002  acc:0.038147\n"
          ]
        }
      ]
    }
  ]
}